{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "291ada4285d81b7724775da889f1025824cfcf5691e48ef89418ffd1713b1d97"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the details entered\n",
    "def print_details():\n",
    "   print(\"The architecture of the model for backpropagation consists of 2 input nuerons, 2 hidden nuerons and one output nueron. A       binary sigmoidal activation function is used on both the hidden and output layers.\")\n",
    "   print(\"The inputs provided for the 2 input neurons are: \")\n",
    "   print(input_data)\n",
    "   print(\"The associated targets are:\")\n",
    "   print(target)\n",
    "   print(\"The weights from input nueron x1 to the 2 hidden nuerons are: \")\n",
    "   print(weights_x1)\n",
    "   print(\"The weights from input nueron x2 to the 2 hidden nuerons are: \")\n",
    "   print(weights_x2)\n",
    "   print(\"The weights from hidden nuerons to the output neuron are: \")\n",
    "   print(hidden_weights)\n",
    "   print(\"The bias for the 2 hidden neurons and the output neuron are: \")\n",
    "   print(bias)\n",
    "   print(\"The learning rate is: \")\n",
    "   print(alpha)\n",
    "   print(\"The algorithm will run for a maximum of \", str(max_epochs),\" epoch(s) or until the target and the calculated output become equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data\n",
    "def input_data():\n",
    "    n = int(input(\"Enter number of input vectors: \"))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(0,n):\n",
    "        raw_str1 = str(input(\"Enter values for vector \" + str(i+1) + \": \"))\n",
    "        input_vector = raw_str1.split(' ')\n",
    "        #print(input_vector)\n",
    "        ip_list = []\n",
    "        for ele in input_vector:\n",
    "            ip_list.append(float(ele))\n",
    "        np_list = np.array(ip_list, dtype=np.float64)\n",
    "        x.append(np_list)\n",
    "        curr_target = str(input(\"Enter the target for vector \" + str(i+1) + \": \"))\n",
    "        y.append(float(curr_target))\n",
    "\n",
    "    return n,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function\n",
    "def act_func(x):\n",
    "    ans = x*-1\n",
    "    ans = math.exp(ans)\n",
    "    ans = ans+1\n",
    "    ans = 1/ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x):\n",
    "    ans = x*-1\n",
    "    ans = math.exp(ans)\n",
    "    a = ans + 1\n",
    "    a = a*a\n",
    "    ans = ans/a\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input learning rate and number of epochs\n",
    "def input_alpha():\n",
    "    alpha = float(input(\"Enter the learning rate for the model\"))\n",
    "    no_of_epochs = int(input(\"Enter the maximum number of epochs for which the model should run\"))\n",
    "    return alpha,no_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input inital weights and bias\n",
    "def input_weights():\n",
    "    raw_str1 = str(input(\"Enter initial weight vector for the input layer from x1: \"))\n",
    "    w_list1 = raw_str1.split(' ')\n",
    "    w1 = []\n",
    "    for ele in w_list1:\n",
    "        w1.append(float(ele))\n",
    "    raw_str2 = str(input(\"Enter initial weight vector for the input layer from x2: \"))\n",
    "    w_list2 = raw_str2.split(' ')\n",
    "    w2 = []\n",
    "    for ele in w_list2:\n",
    "        w2.append(float(ele))\n",
    "    raw_str4 = str(input(\"Enter initial weight vector for the hidden layer: \"))\n",
    "    v_list = raw_str4.split(' ')\n",
    "    v = []\n",
    "    for ele in v_list:\n",
    "        v.append(float(ele))\n",
    "    raw_bias = str(input(\"Enter the value of bias for hidden and output layer\"))\n",
    "    b_list = raw_bias.split(' ')\n",
    "    b = []\n",
    "    for ele in b_list:\n",
    "        b.append(float(ele))\n",
    "    return w1,w2,v,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_error(target, y, yin):\n",
    "    ans = target - y\n",
    "    x = derivative(yin)\n",
    "    return ans*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs, input_vector, target = input_data()      \n",
    "weights_x1,weights_x2,hidden_weights, bias = input_weights()\n",
    "alpha, max_epochs = input_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_details()\n",
    "i = 1\n",
    "flag = 0\n",
    "while(1):\n",
    "    if i>max_epochs:\n",
    "        break\n",
    "    print(\"Epoch: \", str(i))\n",
    "    i = i+1\n",
    "    total_epoch_error= 0.0\n",
    "    for j in range(0,number_of_inputs):\n",
    "        x1 = input_vector[j][0]\n",
    "        x2 = input_vector[j][1]\n",
    "        current_target = target[j]\n",
    "\n",
    "        z1in = x1*weights_x1[0] + x2*weights_x2[0] + bias[0]\n",
    "        z2in = x1*weights_x1[1] + x2*weights_x2[1] + bias[1]\n",
    "\n",
    "        z1 = act_func(z1in)\n",
    "        z2 = act_func(z2in)\n",
    "\n",
    "        yin = z1*hidden_weights[0] + z2*hidden_weights[1] + bias[2]\n",
    "        y = act_func(yin)\n",
    "\n",
    "        #calculation of error between the layers\n",
    "        delta_f_output = out_error(current_target,y,yin)\n",
    "\n",
    "        delta_f_hidden1 = delta_f_output*hidden_weights[0]*derivative(z1in)\n",
    "        delta_f_hidden2 = delta_f_output*hidden_weights[1]*derivative(z2in)\n",
    "\n",
    "        #weight change\n",
    "        weights_x1[0] = alpha*delta_f_hidden1*x1 + weights_x1[0] \n",
    "        weights_x1[1] = alpha*delta_f_hidden2*x1 + weights_x1[1]\n",
    "        weights_x2[0] = alpha*delta_f_hidden1*x2 + weights_x2[0]\n",
    "        weights_x2[1] = alpha*delta_f_hidden2*x2 + weights_x2[1]\n",
    "        bias[0] = bias[0] + alpha*delta_f_hidden1\n",
    "        bias[1] = bias[1] + alpha*delta_f_hidden2\n",
    "        hidden_weights[0] = hidden_weights[0] + alpha*delta_f_output*z1   \n",
    "        hidden_weights[1] = hidden_weights[1] + alpha*delta_f_output*z2\n",
    "        bias[2] = bias[2] + alpha*delta_f_output \n",
    "\n",
    "        if target == y:\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 1:\n",
    "        break\n",
    "    \n",
    "if i<max_epochs:\n",
    "    print(\"The target was reached during the epoch.\")\n",
    "else:\n",
    "    print(\"The model was stopped because it ran for maximum number of epochs entered\")\n",
    "print(\"The final weights from x1 are: \")\n",
    "print(weights_x1)\n",
    "print(\"The final weights from x2 are: \")\n",
    "print(weights_x2)\n",
    "print(\"The final weights from the hidden layer are: \")\n",
    "print(hidden_weights)\n",
    "print(\"The final bias is: \")\n",
    "print(str(bias))"
   ]
  }
 ]
}